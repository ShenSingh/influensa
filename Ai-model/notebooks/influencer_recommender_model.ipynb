{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T14:38:18.451966Z",
     "start_time": "2025-09-18T14:38:17.617658Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from src.data_processor import preprocess_and_combine_data, clean_text # Import functions from our new module\n",
    "\n",
    "# --- Define file paths ---\n",
    "# Make sure 'dataset - Sheet1.csv' is in your 'data/' folder.\n",
    "existing_data_input_path = '../data/dataset - Sheet1.csv'\n",
    "# The combined, preprocessed data will be saved to 'data/combined_preprocessed_influencer_data.csv'\n",
    "output_combined_data_path = '../data/combined_preprocessed_influencer_data.csv'\n",
    "\n",
    "# --- Run the data preprocessing ---\n",
    "# This will load existing data, generate dummy data, combine, clean, and save it.\n",
    "print(\"Starting Data Cleaning and Preprocessing...\")\n",
    "preprocessed_df = preprocess_and_combine_data(\n",
    "    existing_data_path=existing_data_input_path,\n",
    "    output_file_path=output_combined_data_path\n",
    ")\n",
    "\n",
    "if preprocessed_df is not None and not preprocessed_df.empty:\n",
    "    print(\"\\nData preprocessing complete. DataFrame head:\")\n",
    "    print(preprocessed_df.head())\n",
    "    print(f\"Total rows after preprocessing: {len(preprocessed_df)}\")\n",
    "else:\n",
    "    print(\"No preprocessed data available.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Cleaning and Preprocessing...\n",
      "Loaded existing data from ../data/dataset - Sheet1.csv. Initial shape: (599, 8)\n",
      "Combined data. Total shape: (599, 8)\n",
      "\n",
      "Starting data preprocessing...\n",
      "Data preprocessing complete. Final DataFrame head:\n",
      "    platform   username   post_date  \\\n",
      "0  Instagram  shanudrie  07/07/2025   \n",
      "1  Instagram  shanudrie  07/11/2025   \n",
      "2  Instagram  shanudrie  07/10/2025   \n",
      "3  Instagram  shanudrie  07/11/2025   \n",
      "4  Instagram  shanudrie               \n",
      "\n",
      "                                        caption_text post_type  likes  \\\n",
      "0  Back at one of my most favorite go-to spots in...     Video  19300   \n",
      "1  My first time trying crazy fusion food at a fo...     Image  10900   \n",
      "2  Here are the answers from my doctor himself, i...     Video   7749   \n",
      "3  Had a long day? Refresh your self with the sce...     Video   3190   \n",
      "4  Sunday vlogging just got better with the @anch...     Video  17700   \n",
      "\n",
      "   comments                                           hashtags  \\\n",
      "0        58                  #Colombo  #weekends @teatimerocks   \n",
      "1        44  #EGBkemakalawa #NoEGBNoFood #Mawathagama #Kuru...   \n",
      "2        10  #ivdrip #christell #christellskinclinic #chris...   \n",
      "3        24  #ivdrip #christell #christellskinclinic #chris...   \n",
      "4        87  #newmilkshake #readytodrink #ad #shopping #sun...   \n",
      "\n",
      "                                     cleaned_caption  \\\n",
      "0  back at one of my most favorite goto spots in ...   \n",
      "1  my first time trying crazy fusion food at a fo...   \n",
      "2  here are the answers from my doctor himself in...   \n",
      "3  had a long day refresh your self with the scen...   \n",
      "4  sunday vlogging just got better with the ancho...   \n",
      "\n",
      "                                    cleaned_hashtags  \n",
      "0                      colombo weekends teatimerocks  \n",
      "1  egbkemakalawa noegbnofood mawathagama kurunaga...  \n",
      "2  ivdrip christell christellskinclinic christell...  \n",
      "3  ivdrip christell christellskinclinic christell...  \n",
      "4      newmilkshake readytodrink ad shopping sundays  \n",
      "Final data shape after cleaning: (599, 10)\n",
      "\n",
      "Combined and preprocessed data saved to '../data/combined_preprocessed_influencer_data.csv'\n",
      "Columns in the final CSV: ['platform', 'username', 'post_date', 'caption_text', 'post_type', 'likes', 'comments', 'hashtags', 'cleaned_caption', 'cleaned_hashtags']\n",
      "\n",
      "Data preprocessing complete. DataFrame head:\n",
      "    platform   username   post_date  \\\n",
      "0  Instagram  shanudrie  07/07/2025   \n",
      "1  Instagram  shanudrie  07/11/2025   \n",
      "2  Instagram  shanudrie  07/10/2025   \n",
      "3  Instagram  shanudrie  07/11/2025   \n",
      "4  Instagram  shanudrie               \n",
      "\n",
      "                                        caption_text post_type  likes  \\\n",
      "0  Back at one of my most favorite go-to spots in...     Video  19300   \n",
      "1  My first time trying crazy fusion food at a fo...     Image  10900   \n",
      "2  Here are the answers from my doctor himself, i...     Video   7749   \n",
      "3  Had a long day? Refresh your self with the sce...     Video   3190   \n",
      "4  Sunday vlogging just got better with the @anch...     Video  17700   \n",
      "\n",
      "   comments                                           hashtags  \\\n",
      "0        58                  #Colombo  #weekends @teatimerocks   \n",
      "1        44  #EGBkemakalawa #NoEGBNoFood #Mawathagama #Kuru...   \n",
      "2        10  #ivdrip #christell #christellskinclinic #chris...   \n",
      "3        24  #ivdrip #christell #christellskinclinic #chris...   \n",
      "4        87  #newmilkshake #readytodrink #ad #shopping #sun...   \n",
      "\n",
      "                                     cleaned_caption  \\\n",
      "0  back at one of my most favorite goto spots in ...   \n",
      "1  my first time trying crazy fusion food at a fo...   \n",
      "2  here are the answers from my doctor himself in...   \n",
      "3  had a long day refresh your self with the scen...   \n",
      "4  sunday vlogging just got better with the ancho...   \n",
      "\n",
      "                                    cleaned_hashtags  \n",
      "0                      colombo weekends teatimerocks  \n",
      "1  egbkemakalawa noegbnofood mawathagama kurunaga...  \n",
      "2  ivdrip christell christellskinclinic christell...  \n",
      "3  ivdrip christell christellskinclinic christell...  \n",
      "4      newmilkshake readytodrink ad shopping sundays  \n",
      "Total rows after preprocessing: 599\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:38:19.415469Z",
     "start_time": "2025-09-18T14:38:18.485616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# notebooks/influencer_recommender_model.ipynb - New Cell (This is the code you should run now)\n",
    "\n",
    "import pandas as pd\n",
    "# Import the recommend_influencers function from our new src/recommender_utils.py module\n",
    "from src.recommender_utils import recommend_influencers\n",
    "\n",
    "# --- Define User's Business Description ---\n",
    "user_business_description_input = \"book\"\n",
    "\n",
    "# --- Define the path to your preprocessed data file ---\n",
    "# This file was generated in Step 3.\n",
    "preprocessed_data_path = '../data/combined_preprocessed_influencer_data.csv'\n",
    "\n",
    "# --- Run the influencer recommendation process ---\n",
    "print(\"Starting Influencer Recommendation (Feature Extraction & Similarity Calculation)...\")\n",
    "recommended_influencers_df = recommend_influencers(\n",
    "    user_business_description=user_business_description_input,\n",
    "    data_file_path=preprocessed_data_path,\n",
    "    top_n=5 # Number of top influencers to recommend\n",
    ")\n",
    "\n",
    "if recommended_influencers_df is not None:\n",
    "    print(\"\\nRecommendation Process Complete!\")\n",
    "    print(\"Top Recommended Influencers:\")\n",
    "    print(recommended_influencers_df)\n",
    "else:\n",
    "    print(\"Influencer recommendation failed. Please check previous output for errors.\")\n"
   ],
   "id": "3c591eb39213d467",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Influencer Recommendation (Feature Extraction & Similarity Calculation)...\n",
      "Loaded preprocessed data from ../data/combined_preprocessed_influencer_data.csv. Shape: (599, 10)\n",
      "Aggregated content for 20 unique influencers.\n",
      "Influencer profiles (aggregated text & avg engagement) created.\n",
      "\n",
      "Starting TF-IDF Vectorization...\n",
      "TF-IDF vectorization complete. Text data converted to numerical vectors.\n",
      "\n",
      "Starting Cosine Similarity Calculation...\n",
      "Cosine similarity calculation complete. Scores added to DataFrame.\n",
      "\n",
      "Top Recommended Influencers (based on current processing):\n",
      "          username  similarity_score     avg_likes  avg_comments\n",
      "8       luna_peech          0.318635    528.766667     35.366667\n",
      "0   _wildcookbook_          0.000000   5384.133333    136.833333\n",
      "11  praveenaonline          0.000000   7386.600000     52.733333\n",
      "18     vinu_speaks          0.000000   6549.966667    113.466667\n",
      "17  umariaofficial          0.000000  44660.900000   3623.033333\n",
      "\n",
      "Recommendation Process Complete!\n",
      "Top Recommended Influencers:\n",
      "          username                            influencer_profile_text  \\\n",
      "8       luna_peech  these vga cards msigaminglk best ones i saw in...   \n",
      "0   _wildcookbook_  enjoying a delicious homemade sri lankan curry...   \n",
      "11  praveenaonline  if youre heading to kcc before the st of augus...   \n",
      "18     vinu_speaks  loving the freshness of freshjuicelk every mor...   \n",
      "17  umariaofficial  grateful for all your love sharing my new albu...   \n",
      "\n",
      "       avg_likes  avg_comments  similarity_score  \n",
      "8     528.766667     35.366667          0.318635  \n",
      "0    5384.133333    136.833333          0.000000  \n",
      "11   7386.600000     52.733333          0.000000  \n",
      "18   6549.966667    113.466667          0.000000  \n",
      "17  44660.900000   3623.033333          0.000000  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T14:38:19.571710Z",
     "start_time": "2025-09-18T14:38:19.553518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    " # --- Define file paths ---\n",
    "# Make sure 'dataset - Sheet1.csv' is in your 'data/' folder.\n",
    "existing_data_input_path = '../data/dataset - Sheet1.csv'\n",
    "# The combined, preprocessed data will be saved to 'data/combined_preprocessed_influencer_data.csv'\n",
    "output_combined_data_path = '../data/combined_preprocessed_influencer_data.csv'\n",
    "\n",
    "# all influencer username get\n",
    "import pandas as pd\n",
    "\n",
    "def get_score_by_influencer_score(influencer_name):\n",
    "    \"\"\"\n",
    "    Get score and average likes for a specific influencer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the influencer scores CSV\n",
    "        df = pd.read_csv('../data/influencer_scores.csv')\n",
    "\n",
    "        # Filter for the specific influencer\n",
    "        influencer_data = df[df['username'] == influencer_name]\n",
    "\n",
    "        if influencer_data.empty:\n",
    "            print(f\"❌ Influencer '{influencer_name}' not found in the dataset!\")\n",
    "            return None\n",
    "\n",
    "        # Extract the data for the influencer\n",
    "        row = influencer_data.iloc[0]\n",
    "        avg_likes = row['avg_likes']\n",
    "        score = row['score']\n",
    "        total_likes = row['total_likes']\n",
    "        post_count = row['post_count']\n",
    "\n",
    "        # Display the results\n",
    "        print(f\"📊 Influencer: @{influencer_name}\")\n",
    "        print(f\"   💖 Average Likes per Post: {avg_likes:,.0f}\")\n",
    "        print(f\"   🎯 Score: {score:,.2f}\")\n",
    "        print(f\"   ❤️  Total Likes: {total_likes:,.0f}\")\n",
    "        print(f\"   📝 Total Posts: {post_count}\")\n",
    "\n",
    "        return {\n",
    "            'username': influencer_name,\n",
    "            'avg_likes': avg_likes,\n",
    "            'score': score,\n",
    "            'total_likes': total_likes,\n",
    "            'post_count': post_count\n",
    "        }\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: influencer_scores.csv file not found!\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_all_influencer_usernames():\n",
    "    \"\"\"\n",
    "    Extract all unique influencer usernames from the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the data\n",
    "        df = pd.read_csv(output_combined_data_path)\n",
    "\n",
    "        # Get unique usernames\n",
    "        unique_usernames = df['username'].unique()\n",
    "\n",
    "        print(f\"Total unique influencers found: {len(unique_usernames)}\")\n",
    "        print(\"\\nAll Influencer Usernames:\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "\n",
    "        return unique_usernames\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{output_combined_data_path}' not found!\")\n",
    "        return None\n",
    "    except KeyError:\n",
    "        print(\"Error: 'username' column not found in the dataset!\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "get_all_influencer_usernames()\n",
    "\n",
    "# Test the function with some examples\n",
    "print(\"🔍 Testing the function with sample influencers:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with a known influencer from the CSV\n",
    "test_influencer = get_score_by_influencer_score(\"sarangadisasekara\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Test with another influencer\n",
    "test_influencer2 = get_score_by_influencer_score(\"yohanimusic\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Test with a non-existent influencer\n",
    "test_influencer3 = get_score_by_influencer_score(\"nonexistent_user\")\n"
   ],
   "id": "511755ea01a73b30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique influencers found: 20\n",
      "\n",
      "All Influencer Usernames:\n",
      "----------------------------------------\n",
      "🔍 Testing the function with sample influencers:\n",
      "==================================================\n",
      "📊 Influencer: @sarangadisasekara\n",
      "   💖 Average Likes per Post: 230,492\n",
      "   🎯 Score: 345,737.65\n",
      "   ❤️  Total Likes: 6,914,753\n",
      "   📝 Total Posts: 30\n",
      "\n",
      "--------------------------------------------------\n",
      "📊 Influencer: @yohanimusic\n",
      "   💖 Average Likes per Post: 44,720\n",
      "   🎯 Score: 67,080.75\n",
      "   ❤️  Total Likes: 1,341,615\n",
      "   📝 Total Posts: 30\n",
      "\n",
      "--------------------------------------------------\n",
      "❌ Influencer 'nonexistent_user' not found in the dataset!\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
